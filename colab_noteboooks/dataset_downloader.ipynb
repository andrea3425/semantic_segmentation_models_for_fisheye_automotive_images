{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"4t3jr2h1k9-Z","executionInfo":{"status":"ok","timestamp":1711922698915,"user_tz":-120,"elapsed":1285404,"user":{"displayName":"Andrea Vision 2","userId":"09742214702994966908"}}},"outputs":[],"source":["%%capture\n","\n","################################################\n","### This code download the WoodScape Dataset ###\n","################################################\n","\n","# GitHub: https://github.com/valeoai/WoodScape.git\n","#Â Google Drive: https://drive.google.com/drive/folders/1X5JOMEfVlaXfdNy24P8VA-jMs0yzf_HR\n","\n","from pydrive2.auth import GoogleAuth\n","from pydrive2.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# clone the the github repo of the WoodScape dataset\n","!git clone https://github.com/valeoai/WoodScape.git\n","\n","# semantic annotation\n","file_id = '1CBwi0fpDE2G99hHiINTI-AXlOMQSUnb-'\n","downloaded = drive.CreateFile({'id': file_id})\n","downloaded.GetContentFile('semantic_annotations.zip')\n","# instance annotation\n","file_id = '1k9q1k8rh6hghSPFdmxmkZUd_Mip6pt6F'\n","downloaded = drive.CreateFile({'id': file_id})\n","downloaded.GetContentFile('instance_annotations.zip')\n","# rgb images (train data)\n","file_id = '1xQ5J4huNmyK9WPoipHTnuZ7lw_J0xhvL'\n","downloaded = drive.CreateFile({'id': file_id})\n","downloaded.GetContentFile('rgb_images.zip')\n","# rgb images (test data)\n","file_id = '11C9QM3a5Mnu3SO4iJcoQcQzBKMMTU7HL'\n","downloaded = drive.CreateFile({'id': file_id})\n","downloaded.GetContentFile('rgb_images(test_set).zip')\n","\n","# unzip files\n","!unzip /content/semantic_annotations.zip\n","!unzip /content/instance_annotations.zip\n","!unzip /content/rgb_images.zip\n","!unzip /content/rgb_images\\(test_set\\).zip\n","\n","# remove .zip file\n","!rm /content/semantic_annotations.zip\n","!rm /content/instance_annotations.zip\n","!rm /content/rgb_images.zip\n","!rm /content/rgb_images\\(test_set\\).zip\n","\n","# move images' folders into WoodScape/data dir to better organize\n","!mv /content/instance_annotations /content/WoodScape/data\n","!mv /content/semantic_annotations /content/WoodScape/data\n","!mv /content/rgb_images /content/WoodScape/data\n","!mv /content/rgb_images\\(test_set\\) /content/WoodScape/data\n","\n","# generate the semantic segmentation annotations from json instance annotations\n","!python /content/WoodScape/scripts/semantic_map_generator.py --src_path \"/content/WoodScape/data/instance_annotations/\" --dst_path \"/content/WoodScape/data/semantic_annotations\" --semantic_class_mapping \"/content/WoodScape/scripts/configs/semantic_mapping_9_classes.json\" --instance_class_mapping \"/content/WoodScape/scripts/mappers/class_names.json\""]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jcX-uFmsbPQ6","executionInfo":{"status":"ok","timestamp":1711923000260,"user_tz":-120,"elapsed":17375,"user":{"displayName":"Andrea Vision 2","userId":"09742214702994966908"}},"outputId":"ad1d0b16-17f4-4d2d-e0bd-13d0c6171877"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","from shutil import copyfile\n","\n","img_dir='/content/WoodScape/data/rgb_images'\n","annotation_dir='/content/WoodScape/data/semantic_annotations/gtLabels'\n","\n","images = sorted([os.path.join(img_dir, file) for file in os.listdir(img_dir) if file.endswith('.png')])\n","\n","for idx in range(5000, len(images)):\n","    img_path = images[idx]\n","    annotation_path = os.path.join(annotation_dir, os.path.basename(img_path))\n","    img_dest = os.path.join(\"/content/drive/MyDrive/vision_project/dataset/woodscape/data/images\", os.path.basename(img_path))\n","    annotation_dest = os.path.join(\"/content/drive/MyDrive/vision_project/dataset/woodscape/data/semantic_annotations\", os.path.basename(img_path))\n","    copyfile(img_path, img_dest)\n","    copyfile(annotation_path, annotation_dest)"],"metadata":{"id":"9kzQvzrWnb3U","executionInfo":{"status":"ok","timestamp":1711923241068,"user_tz":-120,"elapsed":220699,"user":{"displayName":"Andrea Vision 2","userId":"09742214702994966908"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5FaAKJ-qnayU"},"outputs":[],"source":["%%capture\n","\n","############################################\n","### This code exrtact 3k random examples ###\n","############################################\n","\n","import os\n","import shutil\n","import numpy as np\n","\n","np.random.seed(3)\n","\n","os.mkdir(\"/content/3k_examples\")\n","os.mkdir(\"/content/3k_examples/images\")\n","os.mkdir(\"/content/3k_examples/semantic_annotations\")\n","\n","img_dir='/content/WoodScape/data/rgb_images'\n","annotation_dir='/content/WoodScape/data/semantic_annotations/gtLabels'\n","\n","N_EXAMPLES = 3000\n","\n","idx = np.random.shuffle(np.arange(len(img_dir)))[:N_EXAMPLES]\n","\n","for i in idx:\n","    img = os.listdir(img_dir)[i]\n","    src = os.path.join(img_dir, img)\n","    dst = os.path.join(\"/content/3k_examples/images/\", img)\n","    shutil.copyfile(src, dst)\n","\n","for i in idx:\n","    img = os.listdir(annotation_dir)[i]\n","    src = os.path.join(annotation_dir, img)\n","    dst = os.path.join(\"/content/3k_examples/semantic_annotations/\", img)\n","    shutil.copyfile(src, dst)\n","\n","!zip -r /content/3k_examples.zip /content/3k_examples"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}